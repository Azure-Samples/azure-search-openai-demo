#!/usr/bin/env python3
"""
Scheduler Autom√°tico para Sincronizaci√≥n SharePoint ‚Üí Azure Search
================================================================

Sistema de automatizaci√≥n que ejecuta la sincronizaci√≥n de documentos
de SharePoint con Azure Search usando Document Intelligence de forma programada.

Caracter√≠sticas:
- Ejecuci√≥n autom√°tica cada X horas
- Logging detallado con rotaci√≥n
- Manejo robusto de errores
- Notificaciones de estado
- Control de concurrencia

Autor: Azure Search OpenAI Demo
Fecha: 2025-07-21
"""

import asyncio
import os
import sys
import time
import logging
import signal
from datetime import datetime, timedelta
from typing import Dict, Optional
from pathlib import Path
import json
import threading
from logging.handlers import RotatingFileHandler

# Importar nuestro sincronizador avanzado
from sync_sharepoint_simple_advanced import SharePointAdvancedSync, load_azd_env

class SharePointScheduler:
    """
    Scheduler autom√°tico para sincronizaci√≥n SharePoint
    """
    
    def __init__(self, sync_interval_hours: int = 6, max_files_per_sync: Optional[int] = None):
        self.sync_interval_hours = sync_interval_hours
        self.max_files_per_sync = max_files_per_sync
        self.is_running = False
        self.sync_in_progress = False
        self.last_sync_time = None
        self.sync_stats_history = []
        self.max_history = 10  # Mantener √∫ltimas 10 sincronizaciones
        
        # Configurar logging con rotaci√≥n
        self.setup_logging()
        self.logger = logging.getLogger('sharepoint_scheduler')
        
        # Configurar manejador de se√±ales
        signal.signal(signal.SIGINT, self.signal_handler)
        signal.signal(signal.SIGTERM, self.signal_handler)
        
    def setup_logging(self):
        """Configurar sistema de logging con rotaci√≥n"""
        log_dir = Path("/workspaces/azure-search-openai-demo/logs")
        log_dir.mkdir(exist_ok=True)
        
        # Logger principal
        logger = logging.getLogger('sharepoint_scheduler')
        logger.setLevel(logging.INFO)
        
        # Formatter
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        
        # Handler con rotaci√≥n (10MB m√°ximo, 5 archivos)
        log_file = log_dir / 'sharepoint_scheduler.log'
        file_handler = RotatingFileHandler(
            log_file, 
            maxBytes=10*1024*1024,  # 10MB
            backupCount=5
        )
        file_handler.setFormatter(formatter)
        
        # Handler para consola
        console_handler = logging.StreamHandler(sys.stdout)
        console_handler.setFormatter(formatter)
        
        logger.addHandler(file_handler)
        logger.addHandler(console_handler)
        
        # Evitar duplicados
        logger.propagate = False
        
    def signal_handler(self, signum, frame):
        """Manejador para se√±ales de terminaci√≥n"""
        self.logger.info(f"üì° Se√±al {signum} recibida. Deteniendo scheduler...")
        self.is_running = False
        
    def save_sync_stats(self, stats: Dict):
        """Guardar estad√≠sticas de sincronizaci√≥n"""
        try:
            stats_file = Path("/workspaces/azure-search-openai-demo/logs/sync_stats.json")
            
            # Agregar timestamp
            stats['timestamp'] = datetime.now().isoformat()
            stats['sync_interval_hours'] = self.sync_interval_hours
            
            # Agregar a historial
            self.sync_stats_history.append(stats)
            
            # Mantener solo las √∫ltimas N sincronizaciones
            if len(self.sync_stats_history) > self.max_history:
                self.sync_stats_history = self.sync_stats_history[-self.max_history:]
            
            # Guardar a archivo
            with open(stats_file, 'w') as f:
                json.dump({
                    'last_sync': stats,
                    'history': self.sync_stats_history,
                    'scheduler_config': {
                        'interval_hours': self.sync_interval_hours,
                        'max_files_per_sync': self.max_files_per_sync
                    }
                }, f, indent=2)
                
            self.logger.info(f"üìä Estad√≠sticas guardadas en {stats_file}")
            
        except Exception as e:
            self.logger.error(f"‚ùå Error guardando estad√≠sticas: {e}")
    
    def get_next_sync_time(self) -> datetime:
        """Calcular pr√≥xima hora de sincronizaci√≥n"""
        if self.last_sync_time:
            return self.last_sync_time + timedelta(hours=self.sync_interval_hours)
        else:
            return datetime.now() + timedelta(minutes=1)  # Primera ejecuci√≥n en 1 minuto
    
    def should_sync_now(self) -> bool:
        """Determinar si es hora de sincronizar"""
        if self.sync_in_progress:
            return False
            
        next_sync = self.get_next_sync_time()
        return datetime.now() >= next_sync
    
    async def perform_sync(self) -> Dict:
        """Ejecutar sincronizaci√≥n completa"""
        if self.sync_in_progress:
            self.logger.warning("‚ö†Ô∏è Sincronizaci√≥n ya en progreso, omitiendo...")
            return {"status": "skipped", "reason": "sync_in_progress"}
        
        self.sync_in_progress = True
        sync_start_time = datetime.now()
        
        try:
            self.logger.info("üöÄ Iniciando sincronizaci√≥n autom√°tica SharePoint ‚Üí Azure Search")
            self.logger.info(f"üìÖ Hora: {sync_start_time.strftime('%Y-%m-%d %H:%M:%S')}")
            
            # Crear sincronizador
            sync = SharePointAdvancedSync()
            sync.initialize()
            
            # Ejecutar sincronizaci√≥n
            stats = await sync.sync_documents(
                limit=self.max_files_per_sync,
                dry_run=False
            )
            
            if stats:
                sync_duration = (datetime.now() - sync_start_time).total_seconds()
                
                result = {
                    "status": "success",
                    "start_time": sync_start_time.isoformat(),
                    "duration_seconds": sync_duration,
                    "files_processed": stats.get('processed', 0),
                    "files_total": stats.get('total_files', 0),
                    "errors": stats.get('errors', 0)
                }
                
                self.logger.info(f"‚úÖ Sincronizaci√≥n completada exitosamente")
                self.logger.info(f"üìä Procesados: {result['files_processed']}/{result['files_total']} archivos")
                self.logger.info(f"‚è±Ô∏è Duraci√≥n: {sync_duration:.1f} segundos")
                self.logger.info(f"‚ùå Errores: {result['errors']}")
                
                # Actualizar tiempo de √∫ltima sincronizaci√≥n
                self.last_sync_time = sync_start_time
                
                return result
            else:
                return {
                    "status": "no_files", 
                    "start_time": sync_start_time.isoformat(),
                    "duration_seconds": (datetime.now() - sync_start_time).total_seconds()
                }
                
        except Exception as e:
            sync_duration = (datetime.now() - sync_start_time).total_seconds()
            error_result = {
                "status": "error",
                "start_time": sync_start_time.isoformat(),
                "duration_seconds": sync_duration,
                "error_message": str(e)
            }
            
            self.logger.error(f"‚ùå Error en sincronizaci√≥n autom√°tica: {e}")
            return error_result
            
        finally:
            self.sync_in_progress = False
    
    def print_status(self):
        """Mostrar estado actual del scheduler"""
        now = datetime.now()
        next_sync = self.get_next_sync_time()
        
        self.logger.info(f"üìä Estado del Scheduler:")
        self.logger.info(f"   ‚Ä¢ Ejecut√°ndose: {'S√≠' if self.is_running else 'No'}")
        self.logger.info(f"   ‚Ä¢ Sincronizando: {'S√≠' if self.sync_in_progress else 'No'}")
        self.logger.info(f"   ‚Ä¢ Intervalo: cada {self.sync_interval_hours} horas")
        self.logger.info(f"   ‚Ä¢ L√≠mite archivos: {self.max_files_per_sync or 'Sin l√≠mite'}")
        
        if self.last_sync_time:
            self.logger.info(f"   ‚Ä¢ √öltima sincronizaci√≥n: {self.last_sync_time.strftime('%Y-%m-%d %H:%M:%S')}")
        else:
            self.logger.info(f"   ‚Ä¢ √öltima sincronizaci√≥n: Nunca")
            
        self.logger.info(f"   ‚Ä¢ Pr√≥xima sincronizaci√≥n: {next_sync.strftime('%Y-%m-%d %H:%M:%S')}")
        
        if self.sync_stats_history:
            last_stats = self.sync_stats_history[-1]
            self.logger.info(f"   ‚Ä¢ √öltimo resultado: {last_stats.get('files_processed', 0)} archivos procesados")
    
    async def run(self):
        """Ejecutar scheduler principal"""
        self.is_running = True
        self.logger.info("ü§ñ Iniciando SharePoint Scheduler...")
        self.logger.info(f"‚è∞ Sincronizaci√≥n autom√°tica cada {self.sync_interval_hours} horas")
        
        if self.max_files_per_sync:
            self.logger.info(f"üìÑ L√≠mite: {self.max_files_per_sync} archivos por sincronizaci√≥n")
        
        # Mostrar estado inicial
        self.print_status()
        
        while self.is_running:
            try:
                if self.should_sync_now():
                    # Ejecutar sincronizaci√≥n
                    stats = await self.perform_sync()
                    
                    # Guardar estad√≠sticas
                    self.save_sync_stats(stats)
                    
                    # Mostrar pr√≥xima ejecuci√≥n
                    next_sync = self.get_next_sync_time()
                    self.logger.info(f"‚è∞ Pr√≥xima sincronizaci√≥n: {next_sync.strftime('%Y-%m-%d %H:%M:%S')}")
                
                # Esperar 1 minuto antes de verificar nuevamente
                await asyncio.sleep(60)
                
                # Mostrar estado cada 30 minutos si no hay actividad
                if datetime.now().minute % 30 == 0:
                    self.print_status()
                    
            except KeyboardInterrupt:
                self.logger.info("üõë Deteniendo por interrupci√≥n de teclado...")
                break
            except Exception as e:
                self.logger.error(f"‚ùå Error inesperado en scheduler: {e}")
                await asyncio.sleep(300)  # Esperar 5 minutos antes de reintentar
        
        self.logger.info("üõë SharePoint Scheduler detenido")

async def main():
    """Funci√≥n principal del scheduler"""
    import argparse
    
    parser = argparse.ArgumentParser(description='Scheduler Autom√°tico SharePoint ‚Üí Azure Search')
    parser.add_argument('--interval', type=int, default=6, 
                       help='Intervalo en horas entre sincronizaciones (default: 6)')
    parser.add_argument('--max-files', type=int, 
                       help='M√°ximo n√∫mero de archivos por sincronizaci√≥n')
    parser.add_argument('--test-sync', action='store_true',
                       help='Ejecutar una sincronizaci√≥n de prueba inmediata')
    
    args = parser.parse_args()
    
    try:
        # Verificar variables de entorno
        if not load_azd_env():
            print("‚ùå Error: No se pudieron cargar las variables de entorno")
            sys.exit(1)
        
        scheduler = SharePointScheduler(
            sync_interval_hours=args.interval,
            max_files_per_sync=args.max_files
        )
        
        if args.test_sync:
            # Ejecutar sincronizaci√≥n de prueba
            print("üß™ Ejecutando sincronizaci√≥n de prueba...")
            stats = await scheduler.perform_sync()
            scheduler.save_sync_stats(stats)
            print(f"‚úÖ Prueba completada: {stats}")
        else:
            # Ejecutar scheduler
            await scheduler.run()
            
    except KeyboardInterrupt:
        print("\nüõë Scheduler detenido por usuario")
        sys.exit(0)
    except Exception as e:
        print(f"‚ùå Error cr√≠tico: {e}")
        sys.exit(1)

if __name__ == "__main__":
    asyncio.run(main())
