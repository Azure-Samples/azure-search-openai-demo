# Czat RAG: Dostosowywanie aplikacji czatu

[ Ogldaj: (seria RAG Deep Dive) Dostosowywanie aplikacji](https://www.youtube.com/watch?v=D3slfMqydHc)

> **Wskaz贸wka:** Zalecamy u偶ywanie trybu GitHub Copilot Agent podczas dodawania nowych funkcji lub wprowadzania zmian w kodzie. Ten projekt zawiera plik [AGENTS.md](../AGENTS.pl.md), kt贸ry prowadzi Copilot do generowania kodu zgodnie z konwencjami projektu.

Ten przewodnik zawiera wicej szczeg贸贸w dotyczcych dostosowywania aplikacji czatu RAG.

- [U偶ywanie wasnych danych](#u偶ywanie-wasnych-danych)
- [Dostosowywanie interfejsu u偶ytkownika](#dostosowywanie-interfejsu-u偶ytkownika)
- [Dostosowywanie backendu](#dostosowywanie-backendu)
  - [Podejcia Chat/Ask](#podejcia-chatask)
    - [Podejcie Chat](#podejcie-chat)
    - [Podejcie Ask](#podejcie-ask)
- [Poprawa jakoci odpowiedzi](#poprawa-jakoci-odpowiedzi)
  - [Zidentyfikuj punkt problemu](#zidentyfikuj-punkt-problemu)
  - [Poprawa wynik贸w OpenAI ChatCompletion](#poprawa-wynik贸w-openai-chatcompletion)
  - [Poprawa wynik贸w Azure AI Search](#poprawa-wynik贸w-azure-ai-search)
  - [Ocena jakoci odpowiedzi](#ocena-jakoci-odpowiedzi)

## U偶ywanie wasnych danych

Aplikacja czatu zostaa zaprojektowana do pracy z dowolnymi dokumentami PDF. Przykadowe dane s dostarczone, aby pom贸c Ci szybko rozpocz, ale mo偶esz atwo zastpi je wasnymi danymi. Najpierw bdziesz chcia usun wszystkie istniejce dane, a nastpnie doda wasne. Zobacz [przewodnik po pozyskiwaniu danych](data_ingestion.md) *(angielski)* po wicej szczeg贸贸w.

## Dostosowywanie interfejsu u偶ytkownika

Frontend jest zbudowany przy u偶yciu [React](https://reactjs.org/) i [komponent贸w Fluent UI](https://react.fluentui.dev/). Komponenty frontendu s przechowywane w folderze `app/frontend/src`. Aby zmodyfikowa tytu strony, tekst nag贸wka, przykadowe pytania i inne elementy interfejsu u偶ytkownika, mo偶esz dostosowa plik `app/frontend/src/locales/{en/es/fr/jp/it}/translation.json` dla r贸偶nych jzyk贸w (angielski jest domylny). Podstawowe cigi znak贸w i etykiety u偶ywane w caej aplikacji s zdefiniowane w tych plikach.

## Dostosowywanie backendu

Backend jest zbudowany przy u偶yciu [Quart](https://quart.palletsprojects.com/), frameworka Python dla asynchronicznych aplikacji internetowych. Kod backendu jest przechowywany w folderze `app/backend`. Frontend i backend komunikuj si przez HTTP za pomoc odpowiedzi JSON lub strumieniowanych NDJSON. Dowiedz si wicej w [przewodniku po protokole HTTP](http_protocol.md) *(angielski)*.

### Podejcia Chat/Ask

Zazwyczaj g贸wny kod backendu, kt贸ry bdziesz chcia dostosowa, znajduje si w folderze `app/backend/approaches`, kt贸ry zawiera klasy zasilajce zakadki Chat i Ask. Ka偶da klasa u偶ywa innego podejcia RAG (Retrieval Augmented Generation), kt贸re obejmuj komunikaty systemowe, kt贸re powinny zosta zmienione, aby pasoway do Twoich danych

#### Podejcie Chat

Zakadka czatu u偶ywa podejcia zaprogramowanego w [chatreadretrieveread.py](https://github.com/Azure-Samples/azure-search-openai-demo/blob/main/app/backend/approaches/chatreadretrieveread.py).

1. **Przepisywanie zapytania**: Wywouje API OpenAI ChatCompletion, aby przeksztaci pytanie u偶ytkownika w dobre zapytanie wyszukiwania, u偶ywajc promptu i narzdzi z [chat_query_rewrite.prompty](https://github.com/Azure-Samples/azure-search-openai-demo/blob/main/app/backend/approaches/prompts/chat_query_rewrite.prompty).
2. **Wyszukiwanie**: Odpytuje Azure AI Search o wyniki wyszukiwania dla tego zapytania (opcjonalnie u偶ywajc osadze wektorowych dla tego zapytania).
3. **Odpowiadanie**: Nastpnie wywouje API OpenAI ChatCompletion, aby odpowiedzie na pytanie na podstawie 藕r贸de, u偶ywajc promptu z [chat_answer_question.prompty](https://github.com/Azure-Samples/azure-search-openai-demo/blob/main/app/backend/approaches/prompts/chat_answer_question.prompty). To wywoanie obejmuje r贸wnie偶 histori poprzednich wiadomoci (lub tyle wiadomoci, ile mieci si w limicie token贸w modelu).

Prompty s obecnie dostosowane do przykadowych danych, poniewa偶 zaczynaj si od "Assistant helps the company employees with their healthcare plan questions, and questions about the employee handbook." Zmodyfikuj prompty [chat_query_rewrite.prompty](https://github.com/Azure-Samples/azure-search-openai-demo/blob/main/app/backend/approaches/prompts/chat_query_rewrite.prompty) i [chat_answer_question.prompty](https://github.com/Azure-Samples/azure-search-openai-demo/blob/main/app/backend/approaches/prompts/chat_answer_question.prompty), aby pasoway do Twoich danych.

##### Chat z funkcj multimodaln

Jeli postpowae zgodnie z instrukcjami w [przewodniku multimodalnym](multimodal.pl.md), aby wczy multimodalne RAG,
istnieje kilka r贸偶nic w podejciu czatu:

1. **Przepisywanie zapytania**: Bez zmian.
2. **Wyszukiwanie**: W tym kroku oblicza osadzenie wektorowe dla pytania u偶ytkownika za pomoc [API wektoryzacji tekstu Azure AI Vision](https://learn.microsoft.com/azure/ai-services/computer-vision/how-to/image-retrieval#call-the-vectorize-text-api) i przekazuje to do Azure AI Search, aby por贸wna z polami osadzania obraz贸w w zaindeksowanych dokumentach. Dla ka偶dego pasujcego dokumentu pobiera ka偶dy powizany obraz z Azure Blob Storage i konwertuje go na kodowanie base64.
3. **Odpowiadanie**: Gdy czy wyniki wyszukiwania i pytanie u偶ytkownika, zawiera obrazy zakodowane w base64 i wysya zar贸wno tekst, jak i obrazy do multimodalnego LLM. Model generuje odpowied藕, kt贸ra zawiera cytowania do obraz贸w, a interfejs u偶ytkownika renderuje obrazy, gdy cytowanie jest kliknite.

Ustawienia mo偶na dostosowa, aby wyczy obliczanie osadze wektorowych obraz贸w lub wyczy wysyanie wej obrazowych do LLM, jeli jest to po偶dane.

#### Podejcie Ask

Zakadka ask u偶ywa podejcia zaprogramowanego w [retrievethenread.py](https://github.com/Azure-Samples/azure-search-openai-demo/blob/main/app/backend/approaches/retrievethenread.py).

1. **Wyszukiwanie**: Odpytuje Azure AI Search o wyniki wyszukiwania dla pytania u偶ytkownika (opcjonalnie u偶ywajc osadze wektorowych dla tego pytania).
2. **Odpowiadanie**: Nastpnie czy wyniki wyszukiwania i pytanie u偶ytkownika i wywouje API OpenAI ChatCompletion, aby odpowiedzie na pytanie na podstawie 藕r贸de, u偶ywajc promptu z [ask_answer_question.prompty](https://github.com/Azure-Samples/azure-search-openai-demo/blob/main/app/backend/approaches/prompts/ask_answer_question.prompty).

Prompt dla kroku 2 jest obecnie dostosowany do przykadowych danych, poniewa偶 zaczyna si od "Assistant helps the company employees with their questions about internal documents." Zmodyfikuj [ask_answer_question.prompty](https://github.com/Azure-Samples/azure-search-openai-demo/blob/main/app/backend/approaches/prompts/ask_answer_question.prompty), aby pasowa do Twoich danych.

#### Ask z funkcj multimodaln

Jeli postpowae zgodnie z instrukcjami w [przewodniku multimodalnym](multimodal.pl.md), aby wczy multimodalne RAG,
istnieje kilka r贸偶nic w podejciu ask:

1. **Wyszukiwanie**: W tym kroku r贸wnie偶 oblicza osadzenie wektorowe dla pytania u偶ytkownika za pomoc [API wektoryzacji tekstu Azure AI Vision](https://learn.microsoft.com/azure/ai-services/computer-vision/how-to/image-retrieval#call-the-vectorize-text-api) i przekazuje to do Azure AI Search, aby por贸wna z polami osadzania obraz贸w w zaindeksowanych dokumentach. Dla ka偶dego pasujcego dokumentu pobiera ka偶dy powizany obraz z Azure Blob Storage i konwertuje go na kodowanie base64.
2. **Odpowiadanie**: Gdy czy wyniki wyszukiwania i pytanie u偶ytkownika, zawiera obrazy zakodowane w base64 i wysya zar贸wno tekst, jak i obrazy do multimodalnego LLM. Model generuje odpowied藕, kt贸ra zawiera cytowania do obraz贸w, a interfejs u偶ytkownika renderuje obrazy, gdy cytowanie jest kliknite.

Ustawienia mo偶na dostosowa, aby wyczy obliczanie osadze wektorowych obraz贸w lub wyczy wysyanie wej obrazowych do LLM, jeli jest to po偶dane.

#### Utrwalanie nadpisa ustawie

Interfejs u偶ytkownika zapewnia menu "Developer Settings" do dostosowywania podej, takich jak wyczanie rankera semantycznego lub u偶ywanie wyszukiwania wektorowego.
Te ustawienia s przekazywane w polu "context" 偶dania do backendu i nie s zapisywane na stae.
Jednak jeli znajdziesz ustawienie, kt贸re chcesz uczyni staym, istniej dwa podejcia:

1. Zmie wartoci domylne w frontendzie. Znajdziesz wartoci domylne w `Chat.tsx` i `Ask.tsx`. Na przykad ta linia kodu ustawia domylny tryb wyszukiwania na Hybrid:

    ```typescript
    const [retrievalMode, setRetrievalMode] = useState<RetrievalMode>(RetrievalMode.Hybrid);
    ```

    Mo偶esz zmieni warto domyln na Text, zmieniajc kod na:

    ```typescript
    const [retrievalMode, setRetrievalMode] = useState<RetrievalMode>(RetrievalMode.Text);
    ```

2. Zmie nadpisania w backendzie. Ka偶de z podej ma metod `run`, kt贸ra przyjmuje parametr `context`, a pierwsza linia kodu wyodrbnia nadpisania z tego `context`. Tam mo偶esz nadpisa dowolne ustawienia. Na przykad, aby zmieni tryb wyszukiwania na tekst:

    ```python
    overrides = context.get("overrides", {})
    overrides["retrieval_mode"] = "text"
    ```

    Zmieniajc ustawienie w backendzie, mo偶esz bezpiecznie usun interfejs Developer Settings z frontendu, jeli nie chcesz go udostpnia swoim u偶ytkownikom.

## Poprawa jakoci odpowiedzi

Gdy ju偶 uruchamiasz aplikacj czatu na wasnych danych i z wasnym dostosowanym promptem systemowym,
nastpnym krokiem jest przetestowanie aplikacji za pomoc pyta i odnotowanie jakoci odpowiedzi.
Jeli zauwa偶ysz jakiekolwiek odpowiedzi, kt贸re nie s tak dobre, jak by chcia, oto proces ich poprawy.

### Zidentyfikuj punkt problemu

Pierwszym krokiem jest zidentyfikowanie, gdzie wystpuje problem. Na przykad, jeli u偶ywasz zakadki Chat, problem mo偶e by:

1. API OpenAI ChatCompletion nie generuje dobrego zapytania wyszukiwania na podstawie pytania u偶ytkownika
2. Azure AI Search nie zwraca dobrych wynik贸w wyszukiwania dla zapytania
3. API OpenAI ChatCompletion nie generuje dobrej odpowiedzi na podstawie wynik贸w wyszukiwania i pytania u偶ytkownika

Mo偶esz spojrze na zakadk "Thought process" w aplikacji czatu, aby zobaczy ka偶dy z tych krok贸w
i okreli, kt贸ry jest problemem.

### Poprawa wynik贸w OpenAI ChatCompletion

Jeli problem dotyczy wywoa API ChatCompletion (kroki 1 lub 3 powy偶ej), mo偶esz spr贸bowa zmieni odpowiedni prompt.

Po zmianie promptu upewnij si, 偶e zadajesz to samo pytanie wiele razy, aby sprawdzi, czy og贸lna jako si poprawia, i [uruchom ocen](#ocena-jakoci-odpowiedzi), gdy bdziesz zadowolony ze zmian. API ChatCompletion mo偶e dawa r贸偶ne wyniki za ka偶dym razem, nawet dla temperatury 0.0, ale szczeg贸lnie dla wy偶szej temperatury ni偶 ta (jak nasza domylna 0.7 dla kroku 3).

Mo偶esz r贸wnie偶 spr贸bowa zmieni parametry ChatCompletion, takie jak temperatura, aby sprawdzi, czy to poprawia wyniki dla Twojej domeny.

### Poprawa wynik贸w Azure AI Search

Jeli problem dotyczy Azure AI Search (krok 2 powy偶ej), pierwszym krokiem jest sprawdzenie, jakie parametry wyszukiwania u偶ywasz. Og贸lnie rzecz biorc, najlepsze wyniki znajduj si przy wyszukiwaniu hybrydowym (tekst + wektory) plus dodatkowy krok semantycznego ponownego rankingu, i to wanie wczylimy domylnie. Mo偶e by jednak kilka domen, w kt贸rych ta kombinacja nie jest optymalna. Sprawd藕 ten post na blogu, kt贸ry [ocenia strategie wyszukiwania AI](https://techcommunity.microsoft.com/blog/azure-ai-services-blog/azure-ai-search-outperforming-vector-search-with-hybrid-retrieval-and-ranking-ca/3929167), aby lepiej zrozumie r贸偶nice, lub obejrzyj ten [film RAG Deep Dive o AI Search](https://www.youtube.com/watch?v=ugJy9QkgLYg).

#### Konfigurowanie parametr贸w w aplikacji

Mo偶esz zmieni wiele parametr贸w wyszukiwania w "Developer settings" w frontendzie i sprawdzi, czy wyniki poprawiaj si dla Twoich zapyta. Najbardziej istotne opcje:

![Zrzut ekranu opcji wyszukiwania w ustawieniach deweloperskich](images/screenshot_searchoptions.png)

#### Konfigurowanie parametr贸w w Azure Portal

Mo偶esz uzna za atwiejsze eksperymentowanie z opcjami wyszukiwania za pomoc eksploratora indeksu w Azure Portal.
Otw贸rz zas贸b Azure AI Search, wybierz zakadk Indexes i wybierz tam indeks.

Nastpnie u偶yj widoku JSON eksploratora wyszukiwania i upewnij si, 偶e okrelasz te same opcje, kt贸rych u偶ywasz w aplikacji. Na przykad to zapytanie reprezentuje wyszukiwanie z skonfigurowanym rankerem semantycznym:

```json
{
  "search": "eye exams",
  "queryType": "semantic",
  "semanticConfiguration": "default",
  "queryLanguage": "en-us",
  "speller": "lexicon",
  "top": 3
}
```

Mo偶esz r贸wnie偶 u偶y parametru `highlight`, aby zobaczy, jaki tekst jest dopasowywany w polu `content` w wynikach wyszukiwania.

```json
{
    "search": "eye exams",
    "highlight": "content"
    ...
}
```

![Zrzut ekranu eksploratora wyszukiwania z podwietlonymi wynikami](images/screenshot_searchindex.png)

Eksplorator wyszukiwania dziaa dobrze do testowania tekstu, ale trudniej jest go u偶ywa z wektorami, poniewa偶 musiaby r贸wnie偶 obliczy osadzenie wektorowe i wysa je. Prawdopodobnie atwiej jest u偶ywa frontendu aplikacji do testowania wektor贸w/wyszukiwania hybrydowego.

#### Inne podejcia do poprawy wynik贸w wyszukiwania

Oto dodatkowe sposoby poprawy wynik贸w wyszukiwania:

- Dodanie dodatkowych metadanych do pola "content", takich jak tytu dokumentu, aby mo偶na je byo dopasowa w wynikach wyszukiwania. Zmodyfikuj [searchmanager.py](https://github.com/Azure-Samples/azure-search-openai-demo/blob/main/app/backend/prepdocslib/searchmanager.py), aby uwzgldni wicej tekstu w polu `content`.
- Uczynienie dodatkowych p贸l przeszukiwalnymi przez krok wyszukiwania penotekstowego. Na przykad pole "sourcepage" nie jest obecnie przeszukiwalne, ale mo偶esz uczyni je `SearchableField` z `searchable=True` w [searchmanager.py](https://github.com/Azure-Samples/azure-search-openai-demo/blob/main/app/backend/prepdocslib/searchmanager.py). Taka zmiana wymaga [przebudowania indeksu](https://learn.microsoft.com/azure/search/search-howto-reindex#change-an-index-schema).
- U偶ycie wywoania funkcji do wyszukiwania wedug okrelonych p贸l, takich jak wyszukiwanie wedug nazwy pliku. Zobacz ten post na blogu o [wywoaniu funkcji dla strukturalnego wyszukiwania](https://blog.pamelafox.org/2024/03/rag-techniques-using-function-calling.html).
- U偶ycie innej strategii podziau dla dokument贸w lub modyfikacja istniejcych, aby poprawi fragmenty, kt贸re s indeksowane. Mo偶esz znale藕 obecnie dostpne splitter w [textsplitter.py](https://github.com/Azure-Samples/azure-search-openai-demo/blob/main/app/backend/prepdocslib/textsplitter.py).

### Ocena jakoci odpowiedzi

Po wprowadzeniu zmian do prompt贸w lub ustawie bdziesz chcia rygorystycznie oceni wyniki, aby sprawdzi, czy si poprawiy. Postpuj zgodnie z [przewodnikiem po ocenie](./evaluation.pl.md), aby dowiedzie si, jak uruchamia oceny, przeglda wyniki i por贸wnywa odpowiedzi w r贸偶nych przebiegach.
