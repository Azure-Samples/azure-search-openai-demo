{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.models import QueryType\n",
    "\n",
    "# Replace these with your own values, either in environment variables or directly here\n",
    "AZURE_STORAGE_ACCOUNT = os.environ.get(\"AZURE_STORAGE_ACCOUNT\") or \"mystorageaccount\"\n",
    "AZURE_STORAGE_CONTAINER = os.environ.get(\"AZURE_STORAGE_CONTAINER\") or \"content\"\n",
    "AZURE_SEARCH_SERVICE = os.environ.get(\"AZURE_SEARCH_SERVICE\") or \"gptkb\"\n",
    "AZURE_SEARCH_INDEX = os.environ.get(\"AZURE_SEARCH_INDEX\") or \"gptkbindex\"\n",
    "AZURE_OPENAI_SERVICE = os.environ.get(\"AZURE_OPENAI_SERVICE\") or \"myopenai\"\n",
    "AZURE_OPENAI_GPT_DEPLOYMENT = os.environ.get(\"AZURE_OPENAI_GPT_DEPLOYMENT\") or \"davinci\"\n",
    "AZURE_OPENAI_CHATGPT_DEPLOYMENT = os.environ.get(\"AZURE_OPENAI_CHATGPT_DEPLOYMENT\") or \"chat\"\n",
    "AZURE_OPENAI_CHATGPT_MODEL = os.environ.get(\"AZURE_OPENAI_CHATGPT_MODEL\") or \"gpt-35-turbo\"\n",
    "AZURE_OPENAI_EMB_DEPLOYMENT = os.environ.get(\"AZURE_OPENAI_EMB_DEPLOYMENT\") or \"embedding\"\n",
    "\n",
    "KB_FIELDS_CONTENT = os.environ.get(\"KB_FIELDS_CONTENT\") or \"content\"\n",
    "KB_FIELDS_CATEGORY = os.environ.get(\"KB_FIELDS_CATEGORY\") or \"category\"\n",
    "KB_FIELDS_SOURCEPAGE = os.environ.get(\"KB_FIELDS_SOURCEPAGE\") or \"sourcepage\"\n",
    "\n",
    "# Use the current user identity to authenticate with Azure OpenAI, Cognitive Search and Blob Storage (no secrets needed, \n",
    "# just use 'az login' locally, and managed identity when deployed on Azure). If you need to use keys, use separate AzureKeyCredential instances with the \n",
    "# keys for each service\n",
    "azure_credential = DefaultAzureCredential(exclude_shared_token_cache_credential = True)\n",
    "\n",
    "# Used by the OpenAI SDK\n",
    "openai.api_base = f\"https://{AZURE_OPENAI_SERVICE}.openai.azure.com\"\n",
    "openai.api_version = \"2023-05-15\"\n",
    "\n",
    "# Comment these two lines out if using keys, set your API key in the OPENAI_API_KEY environment variable and set openai.api_type = \"azure\" instead\n",
    "openai.api_type = \"azure_ad\"\n",
    "openai.api_key = azure_credential.get_token(\"https://cognitiveservices.azure.com/.default\").token\n",
    "\n",
    "# Set up clients for Cognitive Search and Storage\n",
    "search_client = SearchClient(\n",
    "    endpoint=f\"https://{AZURE_SEARCH_SERVICE}.search.windows.net\",\n",
    "    index_name=AZURE_SEARCH_INDEX,\n",
    "    credential=azure_credential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chat roles\n",
    "SYSTEM = \"system\"\n",
    "USER = \"user\"\n",
    "ASSISTANT = \"assistant\"\n",
    "\n",
    "system_message_chat_conversation = \"\"\"Assistant helps the company employees with their healthcare plan questions, and questions about the employee handbook. Be brief in your answers.\n",
    "Answer ONLY with the facts listed in the list of sources below. If there isn't enough information below, say you don't know. Do not generate answers that don't use the sources below. If asking a clarifying question to the user would help, ask the question.\n",
    "Each source has a name followed by colon and the actual information, always include the source name for each fact you use in the response. Use square brackets to reference the source, e.g. [info1.txt]. Don't combine sources, list each source separately, e.g. [info1.txt][info2.pdf].\n",
    "\"\"\"\n",
    "chat_conversations = [{\"role\" : SYSTEM, \"content\" : system_message_chat_conversation}]\n",
    "\n",
    "summary_prompt_template = \"\"\"\n",
    "Given the chat history and user question generate a search query that will return the best answer from the knowledge base.\n",
    "Try and generate a grammatical sentence for the search query.\n",
    "Do NOT use quotes and avoid other search operators.\n",
    "Do not include cited source filenames and document names such as info.txt or doc.pdf in the search query terms.\n",
    "Do not include any text inside [] or <<>> in the search query terms.\n",
    "If the question is not in English, translate the question to English before generating the search query.\n",
    "\n",
    "Search query:\n",
    "\"\"\"\n",
    "query_summary_conversations = [{\"role\" : SYSTEM, \"content\" : summary_prompt_template}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute this cell multiple times updating user_input to accumulate chat history\n",
    "user_input = \"Does my plan cover annual eye exams?\"\n",
    "query_summary_conversations.append({\"role\": USER, \"content\": user_input })\n",
    "\n",
    "# Exclude category, to simulate scenarios where there's a set of docs you can't see\n",
    "exclude_category = None\n",
    "\n",
    "query_completion = openai.ChatCompletion.create(\n",
    "    deployment_id=AZURE_OPENAI_CHATGPT_DEPLOYMENT,\n",
    "    model=AZURE_OPENAI_CHATGPT_MODEL,\n",
    "    messages=query_summary_conversations, \n",
    "    temperature=0.7, \n",
    "    max_tokens=1024, \n",
    "    n=1)\n",
    "search = query_completion.choices[0].message.content\n",
    "\n",
    "# Use Azure OpenAI to compute an embedding for the query\n",
    "query_vector = openai.Embedding.create(engine=AZURE_OPENAI_EMB_DEPLOYMENT, input=search)[\"data\"][0][\"embedding\"]\n",
    "\n",
    "# Alternatively simply use the following if not using reranking with semantic search:\n",
    "# search_client.search(search, \n",
    "#                      top=3, \n",
    "#                      vector=query_vector if query_vector else None, \n",
    "#                      top_k=50 if query_vector else None, \n",
    "#                      vector_fields=\"embedding\" if query_vector else None)\n",
    "\n",
    "print(\"Searching:\", search)\n",
    "print(\"-------------------\")\n",
    "filter = \"category ne '{}'\".format(exclude_category.replace(\"'\", \"''\")) if exclude_category else None\n",
    "r = search_client.search(search, \n",
    "                         filter=filter,\n",
    "                         query_type=QueryType.SEMANTIC, \n",
    "                         query_language=\"en-us\", \n",
    "                         query_speller=\"lexicon\", \n",
    "                         semantic_configuration_name=\"default\", \n",
    "                         top=3,\n",
    "                         vector=query_vector if query_vector else None, \n",
    "                         top_k=50 if query_vector else None, \n",
    "                         vector_fields=\"embedding\" if query_vector else None)\n",
    "results = [doc[KB_FIELDS_SOURCEPAGE] + \": \" + doc[KB_FIELDS_CONTENT].replace(\"\\n\", \"\").replace(\"\\r\", \"\") for doc in r]\n",
    "content = \"\\n\".join(results)\n",
    "\n",
    "user_content = user_input + \" \\nSOURCES:\\n\" + content\n",
    "\n",
    "chat_conversations.append({\"role\": USER, \"content\": user_content })\n",
    "\n",
    "chat_completion = openai.ChatCompletion.create(\n",
    "    deployment_id=AZURE_OPENAI_CHATGPT_DEPLOYMENT,\n",
    "    model=AZURE_OPENAI_CHATGPT_MODEL,\n",
    "    messages=chat_conversations, \n",
    "    temperature=0.7, \n",
    "    max_tokens=1024, \n",
    "    n=1)\n",
    "chat_content = chat_completion.choices[0].message.content\n",
    "'''\n",
    "reset user content to avoid sources in conversation history\n",
    "add source as a single shot in query conversation\n",
    "'''\n",
    "chat_conversations[-1][\"content\"] = user_input\n",
    "chat_conversations.append({\"role\":ASSISTANT, \"content\": chat_content})\n",
    "query_summary_conversations.append({\"role\":ASSISTANT, \"content\": chat_content})\n",
    "\n",
    "print(\"\\n-------------------\\n\")\n",
    "for conversation in chat_conversations:\n",
    "    print(conversation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c40b9fc8dfc687e53ddb074d322e19207ef9cf3db51c580aef67976913dea803"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
